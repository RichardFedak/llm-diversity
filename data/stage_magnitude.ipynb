{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: participation, '0' Key Value: 63\n",
      "Field: dataset, '0' Key Value: movies\n",
      "Field: selected_metric, '0' Key Value: BIN-DIV\n",
      "Field: compare_alphas_metric, '0' Key Value: BIN-DIV\n",
      "Field: alphas, '0' Key Value: [0.5, 0.25, 0.99]\n",
      "Field: approx_alphas, '0' Key Value: [0.49, 0.04, 0.99]\n",
      "Field: iteration, '0' Key Value: 1\n",
      "Field: gold, '0' Key Value: [1, 0, 2]\n",
      "Field: selected, '0' Key Value: [1, 0, 2]\n",
      "Field: correct, '0' Key Value: 3\n",
      "Field: disparity, '0' Key Value: 0.04\n",
      "Field: matches, '0' Key Value: True\n",
      "Field: cf_ild, '0' Key Value: [0.5940611021859306, 0.5516173158373151, 0.924095698765346]\n",
      "Field: cb_ild, '0' Key Value: [0.5133367265973773, 0.48402520588466097, 0.6201136452811105]\n",
      "Field: ease_ild, '0' Key Value: [0.986133302961077, 0.9776759828839984, 1.0035031182425362]\n",
      "Field: genres, '0' Key Value: [0.807262625013079, 0.7849408558436802, 0.9175686155046735]\n",
      "Field: tags, '0' Key Value: [0.44975362505231586, 0.40107979093279156, 0.1623034988130842]\n",
      "Field: bin_div, '0' Key Value: [0.8745677109619542, 0.7656373390321717, 0.9606286513992427]\n",
      "Field: relevance, '0' Key Value: [0.08601216, 0.114113346, 0.017436493]\n",
      "Field: relevance_normed, '0' Key Value: [0.99819803, 0.998905, 0.6593102]\n",
      "Field: list1, '0' Key Value: [5699, 12032, 2839, 7456, 1178, 3566, 2095, 1500]\n",
      "Field: list2, '0' Key Value: [10202, 495, 1178, 2709, 8042, 3566, 2839, 6343]\n",
      "Field: list3, '0' Key Value: [9706, 14961, 561, 695, 4967, 11161, 8390, 11175]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('paper_data/drag_drop.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for field, value in data.items():\n",
    "    if isinstance(value, dict) and \"3\" in value:\n",
    "        print(f\"Field: {field}, '0' Key Value: {value['3']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {63: [0, 3], 61: [1, 2], 62: [4, 5], 64: [6, 7], 67: [8, 9], 65: [10, 11], 66: [12, 13], 69: [14, 15], 72: [16, 17], 73: [18, 20], 71: [19, 21], 74: [22, 23], 80: [24, 25], 79: [26, 27], 82: [28, 29], 81: [30, 31], 85: [32, 33], 87: [34, 35], 88: [36, 37], 89: [38, 39], 90: [40, 41], 91: [42, 43], 93: [44, 45], 94: [46, 49], 95: [47, 48], 96: [50, 51], 98: [52, 53], 99: [54, 56], 102: [55, 57], 100: [58, 59], 103: [60, 61], 104: [62, 64], 105: [63, 65], 108: [66, 67], 106: [68, 69], 109: [70, 71], 111: [72, 73], 113: [74, 75], 114: [76, 79], 115: [77, 78], 116: [80, 81], 118: [82, 83], 117: [84, 85], 120: [86, 87], 121: [88, 89], 122: [90, 91], 127: [92, 93], 126: [94, 95], 123: [96, 97], 125: [98, 100], 129: [99, 101], 133: [102, 103], 131: [104, 105], 134: [106, 107], 135: [108, 109], 137: [110, 112], 138: [111, 113], 136: [114, 116], 139: [115, 117], 140: [118, 119], 144: [120, 122], 145: [121, 123], 146: [124, 125], 147: [126, 127], 150: [128, 129], 152: [130, 132], 148: [131, 133], 151: [134, 135], 157: [136, 137], 155: [138, 140], 154: [139, 141], 153: [142, 143], 156: [144, 145], 158: [146, 147], 159: [148, 149], 160: [150, 151], 163: [152, 153], 165: [154, 155], 166: [156, 159], 164: [157, 158], 168: [160, 162], 167: [161, 163], 171: [164, 165], 170: [166, 167], 172: [168, 169], 173: [170, 171], 175: [172, 173], 177: [174, 175], 178: [176, 177], 179: [178, 179], 180: [180, 181], 182: [182, 184], 181: [183, 185], 184: [186, 187], 183: [188, 189], 185: [190, 191], 188: [192, 193], 187: [194, 195], 186: [196, 197], 189: [198, 199], 190: [200, 201], 191: [202, 203], 193: [204, 205], 192: [206, 207], 194: [208, 209], 197: [210, 211], 204: [212, 213], 203: [214, 215], 205: [216, 217], 206: [218, 220], 208: [219, 221], 210: [222, 223], 207: [224, 225], 211: [226, 227], 214: [228, 229], 213: [230, 231], 215: [232, 234], 212: [233, 235], 219: [236, 237], 220: [238, 239], 224: [240, 241], 223: [242, 243], 225: [244, 245], 227: [246, 247], 228: [248, 249], 230: [250, 253], 229: [251, 252], 231: [254, 256], 233: [255, 257], 232: [258, 259], 235: [260, 261], 234: [262, 264], 236: [263, 265], 238: [266, 267], 239: [268, 269], 243: [270, 271], 245: [272, 273], 246: [274, 276], 244: [275, 277], 248: [278, 279], 249: [280, 281], 254: [282, 283], 251: [284, 286], 253: [285, 287], 252: [288, 289], 256: [290, 291], 259: [292, 293], 260: [294, 295], 258: [296, 297], 261: [298, 299], 262: [300, 302], 263: [301, 303], 265: [304, 305], 264: [306, 307], 266: [308, 309], 270: [310, 311], 272: [312, 313], 275: [314, 315], 271: [316, 318], 274: [317, 319], 273: [320, 321], 277: [322, 325], 276: [323, 324], 279: [326, 327], 281: [328, 329], 280: [330, 331], 284: [332, 334], 282: [333, 335], 285: [336, 337], 290: [338, 339], 288: [340, 343], 287: [341, 342], 289: [344, 345], 291: [346, 347], 292: [348, 349], 293: [350, 351], 294: [352, 353], 295: [354, 355], 296: [356, 357], 299: [358, 361], 297: [359, 360], 300: [362, 363], 298: [364, 365], 302: [366, 367], 303: [368, 369], 304: [370, 371], 305: [372, 373], 306: [374, 375], 308: [376, 377], 309: [378, 379], 311: [380, 383], 313: [381, 382], 315: [384, 387], 314: [385, 386], 316: [388, 390], 317: [389, 391], 318: [392, 393], 322: [394, 395], 320: [396, 397], 321: [398, 399], 324: [400, 401], 325: [402, 403], 326: [404, 405], 328: [406, 407], 329: [408, 409], 331: [410, 411], 332: [412, 413], 334: [414, 416], 333: [415, 417], 335: [418, 419], 336: [420, 421], 2: [422, 423], 3: [424, 425], 4: [426, 427], 5: [428, 429], 6: [430, 431]})\n",
      "{'participation': 63, 'dataset': 'movies', 'compare_alphas_metric': 'BIN-DIV', 'alphas': '[0.9, 0.0, 0.01]', 'approx_alphas': '[0.99, 0.49, 0.04]', 'gold': '[1, 2, 0]', 'selected': '[2, 1, 0]', 'list1': [9706, 2709, 3216, 2197, 9493, 3968, 2095, 1500], 'list2': [3000, 4020, 10202, 9426, 5881, 3216, 2709, 4691], 'list3': [10202, 3000, 3216, 4020, 9426, 5881, 2709, 4691], 'cf_ild': '[0.6096736363002232, 0.4549245153154646, 0.4549245153154646]', 'cb_ild': '[0.5423788683755058, 0.4295901911599295, 0.4295901911599295]', 'ease_ild': '[0.9826029368809291, 0.941760608128139, 0.941760608128139]', 'genres': '[0.8868280138288226, 0.6691162926810128, 0.6691163608006069]', 'tags': '[0.3273656027657645, 0.2762046030589512, 0.2762046030589512]', 'bin_div': '[0.9172402315771376, 0.31554257018299486, 0.31554257018299486]'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('paper_data/drag_drop.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def group_by_values(data):\n",
    "\n",
    "    participation = data.get(\"participation\", {})\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for key, value in participation.items():\n",
    "        groups[value].append(int(key))\n",
    "    print(groups)\n",
    "    # groups ---> defaultdict(<class 'list'>, {63: [0, 1, 2], 61: [3, 4, 5], 62: [6, 7, 8]\n",
    "\n",
    "    grouped_indices = list(groups.values())\n",
    "    return grouped_indices\n",
    "\n",
    "\n",
    "fields_to_extract = [\n",
    "    \"participation\", \n",
    "    \"dataset\", \n",
    "    \"compare_alphas_metric\", \n",
    "    \"alphas\", \n",
    "    \"approx_alphas\", \n",
    "    \"gold\", \n",
    "    \"selected\", \n",
    "    \"list1\",\n",
    "    \"list2\",\n",
    "    \"list3\",\n",
    "    \"cf_ild\",\n",
    "    \"cb_ild\",\n",
    "    \"ease_ild\",\n",
    "    \"genres\",\n",
    "    \"tags\",\n",
    "    \"bin_div\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def extract_grouped_values(data):\n",
    "\n",
    "    grouped_indices = group_by_values(data)\n",
    "    \n",
    "    grouped_data = []\n",
    "    for group in grouped_indices:\n",
    "        for index in group:\n",
    "            group_values = {}\n",
    "            for field in fields_to_extract:\n",
    "                group_values[field] = data[field].get(str(index))\n",
    "            grouped_data.append(group_values)\n",
    "    \n",
    "    return grouped_data\n",
    "\n",
    "# Call the function\n",
    "result = extract_grouped_values(data)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"paper_data/magnitude_extracted.json\"\n",
    "\n",
    "with open(output_path, \"w\") as json_file:\n",
    "    json.dump(result, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('paper_data/magnitude_extracted.json', 'r') as file:\n",
    "    magnitude_data = json.load(file)\n",
    "\n",
    "with open('paper_data/movie_data_indexed_full.json', \"r\") as movie_data_file: # https://osf.io/vqcdn/?view_only=972de8061fc4453795622cec2525343epaper_data/\n",
    "    movie_data_indexed = json.load(movie_data_file)\n",
    "\n",
    "with open('paper_data/book_data_indexed_full.json', \"r\") as book_data_file:\n",
    "    book_data_indexed = json.load(book_data_file)\n",
    "\n",
    "movie_index_to_imdb = {}\n",
    "with open('paper_data/df_movies.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        movie_index_to_imdb[int(row['movie_index'])] = int(row['imdb_id'])\n",
    "\n",
    "book_index_to_goodreads = {}\n",
    "with open('paper_data/df_books.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        book_index_to_goodreads[int(row['book_index'])] = int(row['goodreads_id'])\n",
    "\n",
    "movie_title = {}\n",
    "with open(\"paper_data/imdb_movies.json\", 'r') as jsonfile:\n",
    "    movies = json.load(jsonfile)\n",
    "\n",
    "    for movie in movies:\n",
    "        movie_title[int(movie['imdbId'])] = movie['title']\n",
    "\n",
    "book_title = {}\n",
    "with open(\"paper_data/goodreads_titles.csv\", 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        book_title[int(row['goodreads_book_id'])] = row['title']\n",
    "\n",
    "\n",
    "\n",
    "def create_movie_metadata_list(item_ids, data, descriptor):\n",
    "    metadata_list = []\n",
    "    for id in item_ids:\n",
    "        movie_info = data.get(str(id), {})\n",
    "\n",
    "        title = \"\"\n",
    "        if descriptor == \"movie\":\n",
    "            imdb_id = movie_index_to_imdb[id]\n",
    "\n",
    "            title = movie_title[imdb_id]\n",
    "        else:\n",
    "            goodreads_id = book_index_to_goodreads[id]\n",
    "\n",
    "            title = book_title[goodreads_id]\n",
    "        \n",
    "        plot = movie_info.get(\"plot\", [])\n",
    "        if plot:\n",
    "            plot = plot[0]\n",
    "        else:\n",
    "            plot = \"\"\n",
    "\n",
    "        cover = movie_info.get(\"cover\", [])\n",
    "        \n",
    "        genres = \", \".join(movie_info.get(\"genres\", []))\n",
    "        \n",
    "        metadata_list.append({\n",
    "            \"title\": title,\n",
    "            \"plot\": plot,\n",
    "            \"genres\": genres,\n",
    "            \"cover\": cover\n",
    "        })\n",
    "    \n",
    "    return metadata_list\n",
    "\n",
    "final_data_movies = []\n",
    "final_data_books = []\n",
    "\n",
    "for item in magnitude_data:\n",
    "    dataset = item[\"dataset\"]\n",
    "    if dataset == \"movies\":\n",
    "        item[\"list1\"] = create_movie_metadata_list(item[\"list1\"], movie_data_indexed, \"movie\")\n",
    "        item[\"list2\"] = create_movie_metadata_list(item[\"list2\"], movie_data_indexed, \"movie\")\n",
    "        item[\"list3\"] = create_movie_metadata_list(item[\"list3\"], movie_data_indexed, \"movie\")\n",
    "        final_data_movies.append(item)\n",
    "    else:\n",
    "        item[\"list1\"] = create_movie_metadata_list(item[\"list1\"], movie_data_indexed, \"book\")\n",
    "        item[\"list2\"] = create_movie_metadata_list(item[\"list2\"], movie_data_indexed, \"book\")\n",
    "        item[\"list3\"] = create_movie_metadata_list(item[\"list3\"], movie_data_indexed, \"book\")\n",
    "        final_data_books.append(item)\n",
    "\n",
    "\n",
    "movie_output_path = \"./final_data/magnitude_assessment/final_movie_data.json\"\n",
    "book_output_path = \"./final_data/magnitude_assessment/final_book_data.json\"\n",
    "with open(movie_output_path, \"w\") as movie_output_path:\n",
    "    json.dump(final_data_movies, movie_output_path, indent=4)\n",
    "\n",
    "with open(book_output_path, \"w\") as book_output_path:\n",
    "    json.dump(final_data_books, book_output_path, indent=4)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
