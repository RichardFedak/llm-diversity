{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: plot\n",
      "Value: ['A special bond develops between plus-sized inflatable robot Baymax and prodigy Hiro Hamada, who together team up with a group of friends to form a band of high-tech heroes.', 'When a devastating event befalls the city of San Fransokyo and catapults Hiro into the midst of danger, he turns to Baymax and his close friends adrenaline junkie Go Go Tomago, neatnik Wasabi, chemistry whiz Honey Lemon and fanboy Fred. Determined to uncover the mystery, Hiro transforms his friends into a band of high-tech heroes called \"Big Hero 6.\"—Walt Disney Animation Studios', \"Robotics nerd Hiro Hamada discovers an inflatable health care robot Baymax created in the past by his brother, Tadashi. After a terrible life-changing accident, Hiro and Baymax team up with four other nerds and save their hometown San Fransokyo from an evil super villain trying to take over with Hiro's invention.\", 'Hiro is a young boy who graduated at age 14 or 13. Hiro does not know what to do with his life, until he gets some help from his older brother Tadashi. Hiro applies to get in a \"nerd\" college, only to be traumatized. But with the help of Baymax Hamada, Hiro goes on an unexpected journey with some of his friends. Watch as Hiro Hamada takes down an evil villain and some very important people pass away.', \"Robotics prodigy Hiro lives in the city of San Fransokyo. Next to his older brother, Tadashi, Hiro's closest companion is Baymax, a robot whose sole purpose is to take care of people. When a devastating turn of events throws Hiro into the middle of a dangerous plot, he transforms Baymax and his other friends, Go Go Tamago, Wasabi, Honey Lemon and Fred into a band of high-tech heroes.—Jwelch5742\"]\n",
      "\n",
      "\n",
      "Key: cast\n",
      "Value: ['Scott Adsit', 'Ryan Potter', 'Daniel Henney', 'T.J. Miller', 'Jamie Chung', 'Damon Wayans Jr.', 'Genesis Rodriguez', 'James Cromwell', 'Alan Tudyk', 'Maya Rudolph', 'Abraham Benrubi', 'Katie Lowes', 'Billy Bush', 'Daniel Gerson', 'Paul Briggs', 'Charlotte Gulezian', 'David Shaughnessy', 'Kirk Baily', 'Reed Buck', 'June Christopher', 'Cam Clarke', 'Roy Conli', 'Cooper Cowgill', 'David Cowgill', 'Marlie Crisafulli', 'Terri Douglas', 'Jackie Gonneau', 'Nicholas Guest', 'Bridget Hoffman', 'Kelly Hoover', 'Leah Latham', 'James Taku Leung', 'Yuri Lowenthal', 'Tim Mertens', 'Yumi Mizui', 'Brian R. Norris', 'Sundra Oakley', 'Marcella Lentz-Pope', 'Michael Powers', 'Lynwood Robinson', 'Shane Sweet', 'Josie Trinidad', 'Stan Lee']\n",
      "\n",
      "\n",
      "Key: genres\n",
      "Value: ['Animation', 'Action', 'Adventure', 'Comedy', 'Drama', 'Family', 'Fantasy', 'Sci-Fi']\n",
      "\n",
      "\n",
      "Key: rating\n",
      "Value: 7.8\n",
      "\n",
      "\n",
      "Key: year\n",
      "Value: 2014\n",
      "\n",
      "\n",
      "Key: cover\n",
      "Value: https://m.media-amazon.com/images/M/MV5BMDliOTIzNmUtOTllOC00NDU3LWFiNjYtMGM0NDc1YTMxNjYxXkEyXkFqcGdeQXVyNTM3NzExMDQ@.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('paper_data/movie_data_indexed_full.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for field, value in data[\"9706\"].items():\n",
    "    print(f\"Key: {field}\\nValue: {value}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: genres\n",
      "Value: ['Fantasy', 'Young Adult', 'Romance', 'Vampires', 'Fiction', 'Paranormal', 'Paranormal Romance']\n",
      "\n",
      "\n",
      "Key: plot\n",
      "Value: ['As Seattle is ravaged by a string of mysterious killings and a malicious vampire continues her quest for revenge, Bella once again finds herself surrounded by danger. In the midst of it all, she is forced to choose between her love for Edward and her friendship with Jacob - knowing that her decision has the potential to ignite the ageless struggle between vampire and werewolf. With her graduation quickly approaching, Bella has one more decision to make: life or death. But which is which?', 'READERS CAPTIVATED BY', 'AND', 'will eagerly devour', \", the much-anticipated third book in Stephenie Meyer's riveting vampire love saga.\"]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('paper_data/book_data_indexed_full.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for field, value in data[\"49\"].items():\n",
    "    print(f\"Key: {field}\\nValue: {value}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: index, '0' Key Value: 0\n",
      "Field: participation, '0' Key Value: 63\n",
      "Field: dataset, '0' Key Value: movies\n",
      "Field: source_metric, '0' Key Value: CB-ILD\n",
      "Field: position, '0' Key Value: 0\n",
      "Field: items, '0' Key Value: [3000, 2243, 4020, 401, 10202, 2709, 2839, 7783]\n",
      "Field: cf_ild, '0' Key Value: 0.5119669097\n",
      "Field: cb_ild, '0' Key Value: 0.5469276564\n",
      "Field: bin_div, '0' Key Value: 0.3153045886\n",
      "Field: relevance, '0' Key Value: 1.1759650707\n",
      "Field: selected, '0' Key Value: 0\n"
     ]
    }
   ],
   "source": [
    "with open('paper_data/most_diverse_list.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "for field, value in data.items():\n",
    "    if isinstance(value, dict) and \"0\" in value:\n",
    "        print(f\"Field: {field}, '0' Key Value: {value['0']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'participation': [63, 63, 63], 'dataset': ['movies', 'movies', 'movies'], 'source_metric': ['CB-ILD', 'BIN-DIV', 'CF-ILD'], 'items': [[3000, 2243, 4020, 401, 10202, 2709, 2839, 7783], [10202, 3216, 2709, 8042, 1178, 7651, 3566, 6343], [3000, 10202, 2709, 8042, 9426, 4020, 4713, 1178]], 'selected': [0, 1, 0], 'cf_ild': [0.5119669097, 0.5662426608, 0.5681780066], 'cb_ild': [0.5469276564, 0.4653276716, 0.4304229191], 'bin_div': [0.3153045886, 0.7766742432, 0.3846108742]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('paper_data/most_diverse_list.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def group_by_values(data):\n",
    "\n",
    "    participation = data.get(\"participation\", {})\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for key, value in participation.items():\n",
    "        groups[value].append(int(key))\n",
    "\n",
    "    # groups ---> defaultdict(<class 'list'>, {63: [0, 1, 2], 61: [3, 4, 5], 62: [6, 7, 8]\n",
    "\n",
    "    grouped_indices = list(groups.values())\n",
    "    return grouped_indices\n",
    "\n",
    "\n",
    "fields_to_extract = [\"participation\", \"dataset\", \"source_metric\", \"items\", \"selected\", \"cf_ild\", \"cb_ild\", \"bin_div\"]\n",
    "\n",
    "\n",
    "def extract_grouped_values(data):\n",
    "\n",
    "    grouped_indices = group_by_values(data)\n",
    "    \n",
    "    # Create a list of triples where each triple is a list of values from each field for a group of indices\n",
    "    grouped_data = []\n",
    "    for group in grouped_indices:\n",
    "        group_values = {}\n",
    "        for field in fields_to_extract:\n",
    "            # Extract values from each field corresponding to the current group of indices\n",
    "            group_values[field] = [data[field].get(str(index)) for index in group]\n",
    "        grouped_data.append(group_values)\n",
    "    \n",
    "    return grouped_data\n",
    "\n",
    "# Call the function\n",
    "result = extract_grouped_values(data)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"paper_data/mdl_extracted.json\"\n",
    "\n",
    "# Write the result to a JSON file\n",
    "with open(output_path, \"w\") as json_file:\n",
    "    json.dump(result, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n",
      "33\n",
      "36\n",
      "39\n",
      "42\n",
      "45\n",
      "48\n",
      "51\n",
      "54\n",
      "57\n",
      "60\n",
      "63\n",
      "66\n",
      "69\n",
      "72\n",
      "75\n",
      "78\n",
      "81\n",
      "84\n",
      "87\n",
      "90\n",
      "93\n",
      "96\n",
      "99\n",
      "102\n",
      "105\n",
      "108\n",
      "111\n",
      "114\n",
      "117\n",
      "120\n",
      "123\n",
      "126\n",
      "129\n",
      "132\n",
      "135\n",
      "138\n",
      "141\n",
      "144\n",
      "147\n",
      "150\n",
      "153\n",
      "156\n",
      "159\n",
      "162\n",
      "165\n",
      "168\n",
      "171\n",
      "174\n",
      "177\n",
      "180\n",
      "183\n",
      "186\n",
      "189\n",
      "192\n",
      "195\n",
      "198\n",
      "201\n",
      "204\n",
      "207\n",
      "210\n",
      "213\n",
      "216\n",
      "219\n",
      "222\n",
      "225\n",
      "228\n",
      "231\n",
      "234\n",
      "237\n",
      "240\n",
      "243\n",
      "246\n",
      "249\n",
      "252\n",
      "255\n",
      "258\n",
      "261\n",
      "264\n",
      "267\n",
      "270\n",
      "273\n",
      "276\n",
      "279\n",
      "282\n",
      "285\n",
      "288\n",
      "291\n",
      "294\n",
      "297\n",
      "300\n",
      "303\n",
      "306\n",
      "309\n",
      "312\n",
      "315\n",
      "318\n",
      "321\n",
      "324\n",
      "327\n",
      "330\n",
      "333\n",
      "336\n",
      "339\n",
      "342\n",
      "345\n",
      "348\n",
      "351\n",
      "354\n",
      "357\n",
      "360\n",
      "363\n",
      "366\n",
      "369\n",
      "372\n",
      "375\n",
      "378\n",
      "381\n",
      "384\n",
      "387\n",
      "390\n",
      "393\n",
      "396\n",
      "399\n",
      "402\n",
      "405\n",
      "408\n",
      "411\n",
      "414\n",
      "417\n",
      "420\n",
      "423\n",
      "426\n",
      "429\n",
      "432\n",
      "435\n",
      "438\n",
      "441\n",
      "444\n",
      "447\n",
      "450\n",
      "453\n",
      "456\n",
      "459\n",
      "462\n",
      "465\n",
      "468\n",
      "471\n",
      "474\n",
      "477\n",
      "480\n",
      "483\n",
      "486\n",
      "489\n",
      "492\n",
      "495\n",
      "498\n",
      "501\n",
      "504\n",
      "507\n",
      "510\n",
      "513\n",
      "516\n",
      "519\n",
      "522\n",
      "525\n",
      "528\n",
      "531\n",
      "534\n",
      "537\n",
      "540\n",
      "543\n",
      "546\n",
      "549\n",
      "552\n",
      "555\n",
      "558\n",
      "561\n",
      "564\n",
      "567\n",
      "570\n",
      "573\n",
      "576\n",
      "579\n",
      "582\n",
      "585\n",
      "588\n",
      "591\n",
      "594\n",
      "597\n",
      "600\n",
      "603\n",
      "606\n",
      "609\n",
      "612\n",
      "615\n",
      "618\n",
      "621\n",
      "{}\n",
      "624\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "with open('paper_data/mdl_extracted.json', 'r') as file:\n",
    "    mdl_data = json.load(file)\n",
    "\n",
    "with open('paper_data/movie_data_indexed_full.json', \"r\") as movie_data_file: # https://osf.io/vqcdn/?view_only=972de8061fc4453795622cec2525343e\n",
    "    movie_data_indexed = json.load(movie_data_file)\n",
    "\n",
    "with open('paper_data/book_data_indexed_full.json', \"r\") as book_data_file:\n",
    "    book_data_indexed = json.load(book_data_file)\n",
    "\n",
    "movie_index_to_imdb = {}\n",
    "with open('paper_data/df_movies.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        movie_index_to_imdb[int(row['movie_index'])] = int(row['imdb_id'])\n",
    "\n",
    "book_index_to_goodreads = {}\n",
    "with open('paper_data/df_books.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        book_index_to_goodreads[int(row['book_index'])] = int(row['goodreads_id'])\n",
    "\n",
    "movie_title = {}\n",
    "with open(\"paper_data/imdb_movies.json\", 'r') as jsonfile:\n",
    "    movies = json.load(jsonfile)\n",
    "\n",
    "    for movie in movies:\n",
    "        movie_title[int(movie['imdbId'])] = movie['title']\n",
    "\n",
    "book_title = {}\n",
    "with open(\"paper_data/goodreads_titles.csv\", 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        book_title[int(row['goodreads_book_id'])] = row['title']\n",
    "\n",
    "missing_movie_count = {}\n",
    "all_good = True\n",
    "all_good_count = 0\n",
    "totals = 0\n",
    "\n",
    "def create_movie_metadata_list(item_ids, data, descriptor):\n",
    "    global all_good, all_good_count, missing_movie_count, totals\n",
    "    metadata_list = []\n",
    "    all_good = True\n",
    "    for id in item_ids:\n",
    "        movie_info = data.get(str(id), {})\n",
    "\n",
    "        title = \"\"\n",
    "        if descriptor == \"movie\":\n",
    "            imdb_id = movie_index_to_imdb[id]\n",
    "\n",
    "            title = movie_title[imdb_id]\n",
    "        else:\n",
    "            goodreads_id = book_index_to_goodreads[id]\n",
    "\n",
    "            title = book_title[goodreads_id]\n",
    "        \n",
    "        \n",
    "        # if not movie_info:\n",
    "        #     all_good = False\n",
    "        #     name = descriptor + \"_\" + str(movie_id)\n",
    "        #     if name in missing_movie_count:\n",
    "        #         missing_movie_count[name] += 1\n",
    "        #     else:\n",
    "        #         missing_movie_count[name] = 1\n",
    "        \n",
    "        plot = movie_info.get(\"plot\", [])[0]        # \". \".join(movie_info.get(\"plot\", []))\n",
    "        genres = \", \".join(movie_info.get(\"genres\", []))\n",
    "        cover = movie_info.get(\"cover\", \"\")\n",
    "        \n",
    "        metadata_list.append({\n",
    "            \"title\": title,\n",
    "            \"plot\": plot,\n",
    "            \"genres\": genres,\n",
    "            \"cover\": cover\n",
    "        })\n",
    "    if all_good:\n",
    "        all_good_count += 1\n",
    "    totals += 1\n",
    "    \n",
    "    return metadata_list\n",
    "\n",
    "\n",
    "final_data_movies = []\n",
    "final_data_books = []\n",
    "\n",
    "pairs_final_data_movies = []\n",
    "pairs_final_data_books = []\n",
    "\n",
    "options = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "for item in mdl_data:\n",
    "    print(totals)\n",
    "    dataset = item[\"dataset\"][0]\n",
    "    participation = item[\"participation\"][0]\n",
    "    lists = []\n",
    "    if dataset == \"movies\":\n",
    "        lists.append(create_movie_metadata_list(item[\"items\"][0], movie_data_indexed, \"movie\"))\n",
    "        lists.append(create_movie_metadata_list(item[\"items\"][1], movie_data_indexed, \"movie\"))\n",
    "        lists.append(create_movie_metadata_list(item[\"items\"][2], movie_data_indexed, \"movie\"))\n",
    "    else:\n",
    "        lists.append(create_movie_metadata_list(item[\"items\"][0], book_data_indexed, \"book\"))\n",
    "        lists.append(create_movie_metadata_list(item[\"items\"][1], book_data_indexed, \"book\"))\n",
    "        lists.append(create_movie_metadata_list(item[\"items\"][2], book_data_indexed, \"book\"))\n",
    "\n",
    "    selected_index = item[\"selected\"].index(1)\n",
    "\n",
    "    selected_index_cfild = item[\"cf_ild\"].index(max(item[\"cf_ild\"])) # get highest diversity list based on metric values\n",
    "    selected_index_cbild = item[\"cb_ild\"].index(max(item[\"cb_ild\"]))\n",
    "    selected_index_bindiv = item[\"bin_div\"].index(max(item[\"bin_div\"]))\n",
    "\n",
    "    final_object = {\n",
    "        \"dataset\": dataset, \n",
    "        \"participation\": participation,\n",
    "        \"list_A\": lists[0],\n",
    "        \"list_B\": lists[1],\n",
    "        \"list_C\": lists[2],\n",
    "        \"selected_list\": options[selected_index],\n",
    "        \"list_metrics\": item[\"source_metric\"],\n",
    "        \"cf_ild\": options[selected_index_cfild],\n",
    "        \"cb_ild\": options[selected_index_cbild],\n",
    "        \"bin_div\": options[selected_index_bindiv]\n",
    "    }\n",
    "\n",
    "    list_indices = [0,1,2]\n",
    "    list_indices.pop(selected_index)\n",
    "\n",
    "    if dataset == \"movies\":\n",
    "        final_data_movies.append(final_object)\n",
    "        pairs_final_data_movies.append({\n",
    "            \"dataset\": dataset,  \n",
    "            \"list_A\": lists[list_indices[0]],\n",
    "            \"list_B\": lists[selected_index],\n",
    "            \"selected_list\": \"B\"\n",
    "        })\n",
    "        pairs_final_data_movies.append({\n",
    "            \"dataset\": dataset,  \n",
    "            \"list_A\": lists[selected_index],\n",
    "            \"list_B\": lists[list_indices[1]],\n",
    "            \"selected_list\": \"A\"\n",
    "        })\n",
    "    else:\n",
    "        final_data_books.append(final_object)\n",
    "        pairs_final_data_books.append({\n",
    "            \"dataset\": dataset,  \n",
    "            \"list_A\": lists[list_indices[0]],\n",
    "            \"list_B\": lists[selected_index],\n",
    "            \"selected_list\": \"B\"\n",
    "        })\n",
    "        pairs_final_data_books.append({\n",
    "            \"dataset\": dataset,  \n",
    "            \"list_A\": lists[selected_index],\n",
    "            \"list_B\": lists[list_indices[1]],\n",
    "            \"selected_list\": \"A\"\n",
    "        })\n",
    "\n",
    "movie_output_path = \"./final_data/metric_assessment_full/final_movie_data.json\"\n",
    "book_output_path = \"./final_data/metric_assessment_full/final_book_data.json\"\n",
    "with open(movie_output_path, \"w\") as movie_output_path:\n",
    "    json.dump(final_data_movies, movie_output_path, indent=4)\n",
    "\n",
    "with open(book_output_path, \"w\") as book_output_path:\n",
    "    json.dump(final_data_books, book_output_path, indent=4)\n",
    "\n",
    "pairs_movie_output_path = \"./final_data/metric_assessment_pairs/pairs_final_movie_data.json\"\n",
    "pairs_book_output_path = \"./final_data/metric_assessment_pairs/pairs_final_book_data.json\"\n",
    "with open(pairs_movie_output_path, \"w\") as pairs_movie_output_path:\n",
    "    json.dump(pairs_final_data_movies, pairs_movie_output_path, indent=4)\n",
    "\n",
    "with open(pairs_book_output_path, \"w\") as pairs_book_output_path:\n",
    "    json.dump(pairs_final_data_books, pairs_book_output_path, indent=4)\n",
    "\n",
    "print(missing_movie_count)\n",
    "print(all_good_count)\n",
    "print(totals)\n",
    "with open(\"paper_data/missing_data.json\", \"w\") as output_file:\n",
    "    json.dump(missing_movie_count, output_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: index, '0' Key Value: 0\n",
      "Field: participation, '0' Key Value: 61\n",
      "Field: items, '0' Key Value: [1218, 4682, 745, 12886, 9719, 3416, 6387, 2796, 1723, 3738]\n",
      "Field: selected_items, '0' Key Value: [2796, 6387, 12886, 3416, 1723]\n",
      "Field: iteration, '0' Key Value: 0\n",
      "Field: cf_ild, '0' Key Value: 0.4907147302\n",
      "Field: cb_ild, '0' Key Value: 0.5332231734\n",
      "Field: bin_div, '0' Key Value: 0.4570351688\n",
      "Field: relevance, '0' Key Value: 18.3088321686\n",
      "\n",
      "Field: index, '1' Key Value: 0\n",
      "Field: participation, '1' Key Value: 61\n",
      "Field: items, '1' Key Value: [10199, 12644, 1996, 9609, 11478, 12514, 9267, 9312, 5524, 7736]\n",
      "Field: selected_items, '1' Key Value: [9312, 9609, 5524, 10199, 7736]\n",
      "Field: iteration, '1' Key Value: 1\n",
      "Field: cf_ild, '1' Key Value: 0.6580987295\n",
      "Field: cb_ild, '1' Key Value: 0.5086264716\n",
      "Field: bin_div, '1' Key Value: 0.3280315067\n",
      "Field: relevance, '1' Key Value: 14.2006340027\n",
      "\n",
      "Field: index, '2' Key Value: 0\n",
      "Field: participation, '2' Key Value: 61\n",
      "Field: items, '2' Key Value: [6707, 7784, 12259, 9072, 10906, 10193, 4648, 3948, 4565, 1800]\n",
      "Field: selected_items, '2' Key Value: [12259, 1800, 3948, 10193, 10906]\n",
      "Field: iteration, '2' Key Value: 2\n",
      "Field: cf_ild, '2' Key Value: 0.5870876736\n",
      "Field: cb_ild, '2' Key Value: 0.5074966855\n",
      "Field: bin_div, '2' Key Value: 0.2385065884\n",
      "Field: relevance, '2' Key Value: 12.0253839493\n",
      "\n",
      "Field: index, '3' Key Value: 0\n",
      "Field: participation, '3' Key Value: 61\n",
      "Field: items, '3' Key Value: [6877, 4086, 741, 489, 2837, 909, 5155, 8798, 13057, 5401]\n",
      "Field: selected_items, '3' Key Value: [13057, 489, 909, 2837, 8798]\n",
      "Field: iteration, '3' Key Value: 3\n",
      "Field: cf_ild, '3' Key Value: 0.6265886095\n",
      "Field: cb_ild, '3' Key Value: 0.5498350779\n",
      "Field: bin_div, '3' Key Value: 0.5407064939\n",
      "Field: relevance, '3' Key Value: 10.5791320801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO after block q -> q3 odpovede pre blok 6 listov celkové hodnotenie\n",
    "# block key -> aký blok itemov\n",
    "import json\n",
    "\n",
    "with open('paper_data/df_iteration_impressions_selections.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for field, value in data.items():\n",
    "    if isinstance(value, dict) and \"0\" in value:\n",
    "        print(f\"Field: {field}, '0' Key Value: {value['0']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for field, value in data.items():\n",
    "    if isinstance(value, dict) and \"1\" in value:\n",
    "        print(f\"Field: {field}, '1' Key Value: {value['1']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for field, value in data.items():\n",
    "    if isinstance(value, dict) and \"2\" in value:\n",
    "        print(f\"Field: {field}, '2' Key Value: {value['2']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for field, value in data.items():\n",
    "    if isinstance(value, dict) and \"3\" in value:\n",
    "        print(f\"Field: {field}, '3' Key Value: {value['3']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
