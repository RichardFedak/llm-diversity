{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: index, 0 Key Value: 0\n",
      "Field: participation, 0 Key Value: 61\n",
      "Field: items, 0 Key Value: [1218, 4682, 745, 12886, 9719, 3416, 6387, 2796, 1723, 3738]\n",
      "Field: selected_items, 0 Key Value: [2796, 6387, 12886, 3416, 1723]\n",
      "Field: iteration, 0 Key Value: 0\n",
      "Field: cf_ild, 0 Key Value: 0.4907147302\n",
      "Field: cb_ild, 0 Key Value: 0.5332231734\n",
      "Field: bin_div, 0 Key Value: 0.4570351688\n",
      "Field: relevance, 0 Key Value: 18.3088321686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO after block q -> q3 odpovede pre blok 6 listov celkové hodnotenie\n",
    "# q3 DIVERSITY\n",
    "# q4 SERENDIPITY\n",
    "# block key -> aký blok itemov\n",
    "# 3 bloky po 6 recommendations\n",
    "import json\n",
    "\n",
    "with open('paper_data/df_iteration_impressions_selections.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "for i in range(0,1):\n",
    "    for field, value in data.items():\n",
    "        if isinstance(value, dict) and str(i) in value:\n",
    "            print(f\"Field: {field}, {str(i)} Key Value: {value[str(i)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: index, 0 Key Value: 0\n",
      "Field: dataset, 0 Key Value: movies\n",
      "Field: participation, 0 Key Value: 61\n",
      "Field: block, 0 Key Value: 0\n",
      "Field: q1, 0 Key Value: 1.0\n",
      "Field: q2, 0 Key Value: -1.0\n",
      "Field: q3, 0 Key Value: 1.0\n",
      "Field: q4, 0 Key Value: -1.0\n",
      "Field: q5, 0 Key Value: -1.0\n",
      "Field: q6, 0 Key Value: -1.0\n",
      "Field: q7, 0 Key Value: 1.0\n",
      "Field: q8, 0 Key Value: 1.0\n",
      "Field: q9, 0 Key Value: 1.0\n"
     ]
    }
   ],
   "source": [
    "with open('paper_data/after_block_questionnaire.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "for i in range(0,1):\n",
    "    for field, value in data.items():\n",
    "        if isinstance(value, dict) and str(i) in value:\n",
    "            print(f\"Field: {field}, {str(i)} Key Value: {value[str(i)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'participation': [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61], 'iteration': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], 'items': [[1218, 4682, 745, 12886, 9719, 3416, 6387, 2796, 1723, 3738], [10199, 12644, 1996, 9609, 11478, 12514, 9267, 9312, 5524, 7736], [6707, 7784, 12259, 9072, 10906, 10193, 4648, 3948, 4565, 1800], [6877, 4086, 741, 489, 2837, 909, 5155, 8798, 13057, 5401], [8902, 6116, 5772, 7918, 378, 771, 8086, 10399, 43, 2239], [755, 8305, 9038, 5098, 9516, 3954, 14785, 2180, 6988, 1178], [3318, 2389, 8247, 9988, 4135, 7785, 804, 12030, 3431, 7451], [962, 8243, 12621, 7221, 15158, 13304, 13057, 2180, 7918, 15259], [745, 12576, 3779, 6798, 15133, 961, 12644, 5676, 8798, 1513], [9889, 6084, 2239, 13261, 4126, 12514, 742, 4678, 1869, 4493], [13051, 3606, 15634, 728, 6981, 14015, 9341, 4134, 6943, 264], [15169, 1078, 13805, 294, 7043, 12563, 6476, 15292, 1177, 15351], [13057, 11503, 11665, 10160, 13480, 14270, 8557, 14085, 11710, 15158], [351, 14079, 11801, 9013, 14941, 10417, 9742, 12679, 7567, 10261], [10818, 11896, 9972, 14113, 13537, 13099, 12931, 10224, 11737, 14453], [12644, 6602, 1078, 3984, 12857, 10191, 820, 13953, 6118, 9877], [3000, 6387, 10906, 2796, 1163, 4788, 9494, 5401, 1532, 9312], [43, 13248, 13540, 12484, 15637, 11925, 591, 4576, 13007, 317]], 'selected_items': [[2796, 6387, 12886, 3416, 1723], [9312, 9609, 5524, 10199, 7736], [12259, 1800, 3948, 10193, 10906], [13057, 489, 909, 2837, 8798], [8086, 7918], [5098, 9516, 9038, 6988], [3431, 804, 2389, 8247], [13057, 12621, 7918, 8243, 15158], [8798, 6798], [], [15634, 14015], [13805], [13057, 14085, 8557, 15158], [], [9972], [10191], [9312, 1163, 2796, 6387, 10906, 1532], [13540, 591]], 'cf_ild': [0.4907147302, 0.6580987295, 0.5870876736, 0.6265886095, 0.6532863617, 0.655237325, 0.7542792426, 0.8876779344, 0.78464898, 0.7557390849, 0.9065105862, 0.8452657064, 0.9936395433, 0.9942132738, 0.9952022976, 0.8844428168, 0.5141826206, 0.9483292474], 'cb_ild': [0.5332231734, 0.5086264716, 0.5074966855, 0.5498350779, 0.4265190972, 0.5197967953, 0.5246072981, 0.4994173262, 0.5311974419, 0.5094488356, 0.5420201196, 0.5792733934, 0.5271082136, 0.5438680437, 0.5769211663, 0.518124644, 0.505938975, 0.5253233168], 'bin_div': [0.4570351688, 0.3280315067, 0.2385065884, 0.5407064939, 0.1049309669, 0.448333198, 0.4129158095, 0.5483060697, 0.5973475551, 0.4195854772, 0.563858746, 0.3585139816, 0.3084010855, 0.4666871213, 0.4752026154, 0.7294405666, 0.2712652991, 0.662244457]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('paper_data/df_iteration_impressions_selections.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def group_by_values(data):\n",
    "\n",
    "    participation = data.get(\"participation\", {})\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for key, value in participation.items():\n",
    "        groups[value].append(int(key))\n",
    "\n",
    "    grouped_indices = list(groups.values())\n",
    "    return grouped_indices\n",
    "\n",
    "\n",
    "fields_to_extract = [\"participation\", \"iteration\", \"items\", \"selected_items\", \"cf_ild\", \"cb_ild\", \"bin_div\"]\n",
    "\n",
    "\n",
    "def extract_grouped_values(data):\n",
    "\n",
    "    grouped_indices = group_by_values(data)\n",
    "    \n",
    "    grouped_data = []\n",
    "    for group in grouped_indices:\n",
    "        group_values = {}\n",
    "        for field in fields_to_extract:\n",
    "            # Extract values from each field corresponding to the current group of indices\n",
    "            group_values[field] = [data[field].get(str(index)) for index in group]\n",
    "        grouped_data.append(group_values)\n",
    "    \n",
    "    return grouped_data\n",
    "\n",
    "result = extract_grouped_values(data)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'participation': 61, 'block': 0, 'iterations': {0: {'items': [1218, 4682, 745, 12886, 9719, 3416, 6387, 2796, 1723, 3738], 'selected_items': [2796, 6387, 12886, 3416, 1723], 'cf_ild': 0.4907147302, 'cb_ild': 0.5332231734, 'bin_div': 0.4570351688}, 1: {'items': [10199, 12644, 1996, 9609, 11478, 12514, 9267, 9312, 5524, 7736], 'selected_items': [9312, 9609, 5524, 10199, 7736], 'cf_ild': 0.6580987295, 'cb_ild': 0.5086264716, 'bin_div': 0.3280315067}, 2: {'items': [6707, 7784, 12259, 9072, 10906, 10193, 4648, 3948, 4565, 1800], 'selected_items': [12259, 1800, 3948, 10193, 10906], 'cf_ild': 0.5870876736, 'cb_ild': 0.5074966855, 'bin_div': 0.2385065884}, 3: {'items': [6877, 4086, 741, 489, 2837, 909, 5155, 8798, 13057, 5401], 'selected_items': [13057, 489, 909, 2837, 8798], 'cf_ild': 0.6265886095, 'cb_ild': 0.5498350779, 'bin_div': 0.5407064939}, 4: {'items': [8902, 6116, 5772, 7918, 378, 771, 8086, 10399, 43, 2239], 'selected_items': [8086, 7918], 'cf_ild': 0.6532863617, 'cb_ild': 0.4265190972, 'bin_div': 0.1049309669}, 5: {'items': [755, 8305, 9038, 5098, 9516, 3954, 14785, 2180, 6988, 1178], 'selected_items': [5098, 9516, 9038, 6988], 'cf_ild': 0.655237325, 'cb_ild': 0.5197967953, 'bin_div': 0.448333198}}}\n"
     ]
    }
   ],
   "source": [
    "def transform_data(data_list):\n",
    "    transformed_data = []\n",
    "    \n",
    "    for data in data_list:\n",
    "        participation_blocks = [data['participation'][i:i+6] for i in range(0, len(data['participation']), 6)]\n",
    "        \n",
    "        for block_index, block in enumerate(participation_blocks):\n",
    "            output_obj = {\n",
    "                'participation': block[0],\n",
    "                'block': block_index\n",
    "            }\n",
    "            \n",
    "            iterations = {}\n",
    "            for iteration in data['iteration'][block_index*6:block_index*6+6]:\n",
    "                iterations[iteration] = {\n",
    "                    'items': data['items'][iteration],\n",
    "                    'selected_items': data['selected_items'][iteration],\n",
    "                    'cf_ild': data['cf_ild'][iteration],\n",
    "                    'cb_ild': data['cb_ild'][iteration],\n",
    "                    'bin_div': data['bin_div'][iteration]\n",
    "                }\n",
    "            \n",
    "            output_obj['iterations'] = iterations\n",
    "            transformed_data.append(output_obj)\n",
    "            \n",
    "    return transformed_data\n",
    "\n",
    "result = transform_data(result)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'participation': 61, 'block': 0, 'dataset': 'movies', 'diversity_score': 1.0, 'serendipity_score': -1.0}, {'participation': 63, 'block': 0, 'dataset': 'movies', 'diversity_score': 2.0, 'serendipity_score': 3.0}, {'participation': 61, 'block': 1, 'dataset': 'movies', 'diversity_score': -1.0, 'serendipity_score': -1.0}, {'participation': 61, 'block': 2, 'dataset': 'movies', 'diversity_score': 1.0, 'serendipity_score': -1.0}, {'participation': 63, 'block': 1, 'dataset': 'movies', 'diversity_score': -2.0, 'serendipity_score': -2.0}, {'participation': 62, 'block': 0, 'dataset': 'movies', 'diversity_score': 1.0, 'serendipity_score': 3.0}]\n"
     ]
    }
   ],
   "source": [
    "with open('paper_data/after_block_questionnaire.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def create_combined_json(data):\n",
    "    combined_data = []\n",
    "\n",
    "    for i in range(len(data['participation'])):\n",
    "        combined_data.append({\n",
    "            'participation': data['participation'][str(i)], \n",
    "            'block': data['block'][str(i)], \n",
    "            'dataset': data['dataset'][str(i)],\n",
    "            'diversity_score': data['q3'][str(i)], \n",
    "            'serendipity_score': data['q4'][str(i)] \n",
    "        })\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "questions = create_combined_json(data)\n",
    "print(questions[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'participation': 61, 'block': 0, 'iterations': {0: {'items': [1218, 4682, 745, 12886, 9719, 3416, 6387, 2796, 1723, 3738], 'selected_items': [2796, 6387, 12886, 3416, 1723], 'cf_ild': 0.4907147302, 'cb_ild': 0.5332231734, 'bin_div': 0.4570351688}, 1: {'items': [10199, 12644, 1996, 9609, 11478, 12514, 9267, 9312, 5524, 7736], 'selected_items': [9312, 9609, 5524, 10199, 7736], 'cf_ild': 0.6580987295, 'cb_ild': 0.5086264716, 'bin_div': 0.3280315067}, 2: {'items': [6707, 7784, 12259, 9072, 10906, 10193, 4648, 3948, 4565, 1800], 'selected_items': [12259, 1800, 3948, 10193, 10906], 'cf_ild': 0.5870876736, 'cb_ild': 0.5074966855, 'bin_div': 0.2385065884}, 3: {'items': [6877, 4086, 741, 489, 2837, 909, 5155, 8798, 13057, 5401], 'selected_items': [13057, 489, 909, 2837, 8798], 'cf_ild': 0.6265886095, 'cb_ild': 0.5498350779, 'bin_div': 0.5407064939}, 4: {'items': [8902, 6116, 5772, 7918, 378, 771, 8086, 10399, 43, 2239], 'selected_items': [8086, 7918], 'cf_ild': 0.6532863617, 'cb_ild': 0.4265190972, 'bin_div': 0.1049309669}, 5: {'items': [755, 8305, 9038, 5098, 9516, 3954, 14785, 2180, 6988, 1178], 'selected_items': [5098, 9516, 9038, 6988], 'cf_ild': 0.655237325, 'cb_ild': 0.5197967953, 'bin_div': 0.448333198}}, 'diversity_score': 1.0, 'serendipity_score': -1.0, 'dataset': 'movies'}\n"
     ]
    }
   ],
   "source": [
    "def append_scores_to_result(result, questions):\n",
    "    for item in result:\n",
    "        participation = item['participation']\n",
    "        block = item['block']\n",
    "        \n",
    "        for question in questions:\n",
    "            if question['participation'] == participation and question['block'] == block:\n",
    "                item['diversity_score'] = question['diversity_score']\n",
    "                item['serendipity_score'] = question['serendipity_score']\n",
    "                item['dataset'] = question['dataset']\n",
    "                break\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "result = append_scores_to_result(result, questions)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "with open('paper_data/movie_data_indexed_full.json', \"r\") as movie_data_file: # https://osf.io/vqcdn/?view_only=972de8061fc4453795622cec2525343epaper_data/\n",
    "    movie_data_indexed = json.load(movie_data_file)\n",
    "\n",
    "with open('paper_data/book_data_indexed_full.json', \"r\") as book_data_file:\n",
    "    book_data_indexed = json.load(book_data_file)\n",
    "\n",
    "movie_index_to_imdb = {}\n",
    "with open('paper_data/df_movies.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        movie_index_to_imdb[int(row['movie_index'])] = int(row['imdb_id'])\n",
    "\n",
    "book_index_to_goodreads = {}\n",
    "with open('paper_data/df_books.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        book_index_to_goodreads[int(row['book_index'])] = int(row['goodreads_id'])\n",
    "\n",
    "movie_title = {}\n",
    "with open(\"paper_data/imdb_movies.json\", 'r') as jsonfile:\n",
    "    movies = json.load(jsonfile)\n",
    "\n",
    "    for movie in movies:\n",
    "        movie_title[int(movie['imdbId'])] = movie['title']\n",
    "\n",
    "book_title = {}\n",
    "with open(\"paper_data/goodreads_titles.csv\", 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        book_title[int(row['goodreads_book_id'])] = row['title']\n",
    "\n",
    "\n",
    "\n",
    "def create_movie_metadata_list(item_ids, data, descriptor):\n",
    "    metadata_list = []\n",
    "    for id in item_ids:\n",
    "        movie_info = data.get(str(id), {})\n",
    "\n",
    "        title = \"\"\n",
    "        if descriptor == \"movie\":\n",
    "            imdb_id = movie_index_to_imdb[id]\n",
    "\n",
    "            title = movie_title[imdb_id]\n",
    "        else:\n",
    "            goodreads_id = book_index_to_goodreads[id]\n",
    "\n",
    "            title = book_title[goodreads_id]\n",
    "        \n",
    "        plot = movie_info.get(\"plot\", [])\n",
    "        if plot:\n",
    "            plot = plot[0]\n",
    "        else:\n",
    "            plot = \"\"\n",
    "\n",
    "        cover = movie_info.get(\"cover\", [])\n",
    "        \n",
    "        genres = \", \".join(movie_info.get(\"genres\", []))\n",
    "        \n",
    "        metadata_list.append({\n",
    "            \"title\": title,\n",
    "            \"plot\": plot,\n",
    "            \"genres\": genres,\n",
    "            \"cover\": cover\n",
    "        })\n",
    "    \n",
    "    return metadata_list\n",
    "\n",
    "\n",
    "books_data = []\n",
    "movies_data = []\n",
    "\n",
    "for item in result:\n",
    "    if item['dataset'] == 'books':\n",
    "        books_data.append(item)\n",
    "    elif item['dataset'] == 'movies':\n",
    "        movies_data.append(item)\n",
    "\n",
    "def replace_ids_with_metadata_in_iterations(data, descriptor):\n",
    "    for item in data:\n",
    "        iterations = item['iterations']\n",
    "        \n",
    "        # Loop through all iterations\n",
    "        for key, iteration in iterations.items():\n",
    "            # Replace 'items' with metadata\n",
    "            iteration['items'] = create_movie_metadata_list(iteration['items'], \n",
    "                                                            movie_data_indexed if descriptor == \"movie\" else book_data_indexed, \n",
    "                                                            descriptor)\n",
    "            # Replace 'selected_items' with metadata\n",
    "            iteration['selected_items'] = create_movie_metadata_list(iteration['selected_items'], \n",
    "                                                                     movie_data_indexed if descriptor == \"movie\" else book_data_indexed, \n",
    "                                                                     descriptor)\n",
    "    \n",
    "    return data\n",
    "\n",
    "movies_data = replace_ids_with_metadata_in_iterations(movies_data, \"movie\")\n",
    "books_data = replace_ids_with_metadata_in_iterations(books_data, \"book\")\n",
    "\n",
    "\n",
    "os.makedirs('./final_data/recommendations', exist_ok=True)\n",
    "\n",
    "with open('./final_data/recommendations/final_book_data.json', 'w') as book_file:\n",
    "    json.dump(books_data, book_file, indent=4)\n",
    "\n",
    "with open('./final_data/recommendations/final_movie_data.json', 'w') as movie_file:\n",
    "    json.dump(movies_data, movie_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
