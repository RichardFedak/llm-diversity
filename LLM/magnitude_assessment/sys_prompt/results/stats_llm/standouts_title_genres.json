{
    "name": "standouts_title_genres",
    "total_evaluations": 222,
    "llm_output": {
        "correct_evaluations": {
            "output": 54,
            "cf_ild": 77,
            "cb_ild": 75,
            "bin_div": 66
        },
        "accuracy": {
            "output": 0.2432,
            "cf_ild": 0.3468,
            "cb_ild": 0.3378,
            "bin_div": 0.2973
        }
    },
    "user_output": {
        "correct_evaluations": {
            "cf_ild": 64,
            "cb_ild": 61,
            "bin_div": 53
        },
        "accuracy": {
            "cf_ild": 0.2883,
            "cb_ild": 0.2748,
            "bin_div": 0.2387
        }
    },
    "correct_output_metric_counts": {
        "BIN-DIV": 18,
        "CB-ILD": 24,
        "CF-ILD": 12
    },
    "emd": 0.24016516516516515,
    "spearman": 0.16511579271392718,
    "spearman_final_ordering": 0.11261261261261261
}