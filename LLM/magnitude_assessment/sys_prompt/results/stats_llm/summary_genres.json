{
    "name": "summary_genres",
    "total_evaluations": 222,
    "llm_output": {
        "correct_evaluations": {
            "output": 54,
            "cf_ild": 55,
            "cb_ild": 60,
            "bin_div": 61
        },
        "accuracy": {
            "output": 0.2432,
            "cf_ild": 0.2477,
            "cb_ild": 0.2703,
            "bin_div": 0.2748
        }
    },
    "user_output": {
        "correct_evaluations": {
            "cf_ild": 64,
            "cb_ild": 61,
            "bin_div": 53
        },
        "accuracy": {
            "cf_ild": 0.2883,
            "cb_ild": 0.2748,
            "bin_div": 0.2387
        }
    },
    "correct_output_metric_counts": {
        "CF-ILD": 16,
        "BIN-DIV": 19,
        "CB-ILD": 19
    },
    "emd": 0.2682582582582582,
    "spearman": 0.1311448949893332,
    "spearman_final_ordering": 0.10585585585585586,
    "mean_absolute_error": 0.32969969969969976
}