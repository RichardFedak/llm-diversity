{
    "name": "summary_title_genres",
    "total_evaluations": 222,
    "llm_output": {
        "correct_evaluations": {
            "output": 50,
            "cf_ild": 57,
            "cb_ild": 54,
            "bin_div": 58
        },
        "accuracy": {
            "output": 0.2252,
            "cf_ild": 0.2568,
            "cb_ild": 0.2432,
            "bin_div": 0.2613
        }
    },
    "user_output": {
        "correct_evaluations": {
            "cf_ild": 64,
            "cb_ild": 61,
            "bin_div": 53
        },
        "accuracy": {
            "cf_ild": 0.2883,
            "cb_ild": 0.2748,
            "bin_div": 0.2387
        }
    },
    "correct_output_metric_counts": {
        "BIN-DIV": 20,
        "CB-ILD": 18,
        "CF-ILD": 12
    },
    "emd": 0.2682582582582582,
    "spearman": 0.09197233983233538,
    "spearman_final_ordering": 0.0472972972972973
}