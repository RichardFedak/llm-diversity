{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56f0657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from ollama import chat\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from loader_clone import create_loaders\n",
    "\n",
    "from representant_base import (\n",
    "    Representant,\n",
    "    DiversityStimulus,\n",
    "    RepresentantGenerator,\n",
    "    GenresDiversityHandler,\n",
    "    PlotDiversityHandler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93f0678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\richa\\Desktop\\SCHOOL\\mgr\\diplomka\\experiment\\EasyStudy\\server\\static\\datasets\\ml-latest\\loader_clone.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  loader.ratings_df.loc[:, \"ratings_per_year\"] = loader.ratings_df['movieId'].map(loader.ratings_df['movieId'].value_counts()) / loader.ratings_df['movieId'].map(movies_df_indexed[\"age\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape after filtering: (3536742, 5), n_users = 9612, n_items = 1525\n",
      "2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\richa\\Desktop\\SCHOOL\\mgr\\diplomka\\experiment\\EasyStudy\\server\\static\\datasets\\ml-latest\\loader_clone.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  loader.ratings_df.loc[:, \"ratings_per_year\"] = loader.ratings_df['movieId'].map(loader.ratings_df['movieId'].value_counts()) / loader.ratings_df['movieId'].map(movies_df_indexed[\"age\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape after filtering: (8146440, 5), n_users = 34683, n_items = 9456\n"
     ]
    }
   ],
   "source": [
    "_, loader = create_loaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e44f69a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  item  rating\n",
      "0    16    74     1.0\n",
      "1    16    86     1.5\n",
      "2    16   213     1.0\n",
      "3    16   313     2.0\n",
      "4    16   347     1.0\n"
     ]
    }
   ],
   "source": [
    "# mapping for filtered dataset...\n",
    "movie_ids = sorted(loader.ratings_df.movieId.unique())\n",
    "id2idx = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "idx2id = {i: mid for mid, i in id2idx.items()}\n",
    "\n",
    "# rename cols as in EasyStudy and map movieId to indices\n",
    "ratings_mapped = (\n",
    "    loader.ratings_df\n",
    "    .rename(columns={\"userId\": \"user\",\n",
    "                     \"movieId\": \"item\",\n",
    "                     \"rating\": \"rating\"})\n",
    "    .assign(item=lambda x: x[\"item\"].map(id2idx))\n",
    "    [[\"user\", \"item\", \"rating\"]]\n",
    "    .astype({\"user\": int, \"item\": int, \"rating\": float})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "loader.ratings_df = ratings_mapped\n",
    "\n",
    "print(ratings_mapped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80a7c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quantile_transform(scores, output_distribution=\"normal\"):\n",
    "    # Map scores to a specified distribution using quantile transformation\n",
    "    qt = QuantileTransformer(output_distribution=output_distribution, random_state=42)\n",
    "    scores_q = qt.fit_transform(scores)\n",
    "    # Return both transformed scores and the transformer object\n",
    "    return scores_q, qt\n",
    "\n",
    "class LLMProfiling():\n",
    "\n",
    "    def __init__(self, loader, positive_threshold, l2, **kwargs):\n",
    "        self._ratings_df = None\n",
    "        self._loader = None\n",
    "        self._all_items = None\n",
    "\n",
    "        self._model = None\n",
    "\n",
    "        self._hdbscan_clusterer = None\n",
    "\n",
    "        self.stimulus_handlers: dict[DiversityStimulus, type[RepresentantGenerator]] = {\n",
    "            DiversityStimulus.GENRES: GenresDiversityHandler,\n",
    "            DiversityStimulus.PLOT: PlotDiversityHandler,\n",
    "        }\n",
    "\n",
    "        self.diversity_stimulus = None\n",
    "\n",
    "        self._rating_matrix = None\n",
    "\n",
    "        self._threshold = positive_threshold\n",
    "        self._l2 = l2\n",
    "\n",
    "        self._items_count = None\n",
    "\n",
    "        self._weights = None\n",
    "        self._max_clusters = None\n",
    "\n",
    "    def fit(self, loader):\n",
    "\n",
    "        self._ratings_df = loader.ratings_df\n",
    "        self._loader = loader\n",
    "        self._all_items = self._ratings_df.item.unique()\n",
    "\n",
    "        self._model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "        self._hdbscan_clusterer = HDBSCAN(\n",
    "            min_cluster_size=3,\n",
    "            min_samples=None,\n",
    "            metric='cosine',\n",
    "        )\n",
    "\n",
    "        self._rating_matrix = (\n",
    "            self._loader.ratings_df.pivot(index=\"user\", columns=\"item\", values=\"rating\")\n",
    "            .fillna(0)\n",
    "            .values\n",
    "        )\n",
    "\n",
    "        self._items_count =  np.shape(self._rating_matrix)[1]\n",
    "\n",
    "        X = np.where(self._rating_matrix >= self._threshold, 1, 0).astype(np.float32)\n",
    "\n",
    "        # Compute Gram matrix (G = X^T @ X)\n",
    "        G = X.T @ X\n",
    "        G += self._l2 * np.eye(self._items_count)  # Regularization\n",
    "\n",
    "        # Compute the inverse of G\n",
    "        P = np.linalg.inv(G)\n",
    "\n",
    "        # Compute B matrix\n",
    "        diag_P = np.diag(P)\n",
    "        B = P / (-diag_P[:, None])  # Normalize rows by diagonal elements\n",
    "        np.fill_diagonal(B, 0)  # Set diagonal to zero\n",
    "        print(\"B matrix computed\")\n",
    "        self._weights = B\n",
    "        self._max_clusters = 2\n",
    "\n",
    "    # Predict for the user\n",
    "    def predict(self, selected_items, filter_out_items, k, dominant_stimulus_weight, dominant_stimulus):\n",
    "        #print(\"Selected\", selected_items)\n",
    "        #print(\"Filter out\", filter_out_items)\n",
    "\n",
    "        indices = list(selected_items)\n",
    "        user_vector = np.zeros((self._items_count,), dtype=np.float32)\n",
    "        for i in indices:\n",
    "            user_vector[i] = 1.0\n",
    "\n",
    "        relevance_scores = np.dot(user_vector, self._weights)\n",
    "        relevance_scores = apply_quantile_transform(relevance_scores.reshape(-1, 1), output_distribution='normal')[0].flatten()\n",
    "\n",
    "        MAX_CLUSTERS = 3\n",
    "        \n",
    "        self.diversity_stimulus = dominant_stimulus\n",
    "        if self.diversity_stimulus == DiversityStimulus.GENRES:\n",
    "            genre_weight = dominant_stimulus_weight\n",
    "            plot_weight = 1 - dominant_stimulus_weight\n",
    "        else:\n",
    "            plot_weight = dominant_stimulus_weight\n",
    "            genre_weight = 1 - dominant_stimulus_weight\n",
    "\n",
    "        # Prepare user-preferred movies based on selected items\n",
    "        user_preferred_movies = []\n",
    "        for item in selected_items:\n",
    "            user_preferred_movies.append(self._loader.movies_df.iloc[item])\n",
    "\n",
    "        # #print(\"PREF MOVIES:\", user_preferred_movies)\n",
    "\n",
    "        # Update the final embedding calculation with the genre and plot weights\n",
    "        final_embedding = genre_weight * self._loader.genres_embeddings + plot_weight * self._loader.plot_embeddings\n",
    "        #print(\"final embed shape\", final_embedding.shape)\n",
    "        \n",
    "        mask = np.ones(final_embedding.shape[0], dtype=bool)\n",
    "        mask[filter_out_items] = 0\n",
    "        relevance_scores[filter_out_items] = 0\n",
    "        original_indices = np.where(mask)[0]\n",
    "        emb_matrix = final_embedding[mask]\n",
    "        \n",
    "        user_genre_embeddings = self._model.encode([movie['genres'] for movie in user_preferred_movies])\n",
    "        user_plot_embeddings = self._model.encode([movie['plot'] for movie in user_preferred_movies])\n",
    "        user_embeddings = genre_weight * user_genre_embeddings + plot_weight * user_plot_embeddings\n",
    "        #print(user_embeddings.shape)\n",
    "\n",
    "        #print(\"clustering\")\n",
    "        \n",
    "        cluster_labels = self._hdbscan_clusterer.fit_predict(user_embeddings)\n",
    "        #print(\"clustering DONE\")\n",
    "        print(cluster_labels)\n",
    "        clusters = {}\n",
    "\n",
    "        if len(np.unique(cluster_labels)) == 1: # No clusters found sample randomly\n",
    "            random_indices = np.random.choice(len(user_preferred_movies), size=min(len(user_preferred_movies),self._max_clusters), replace=False)\n",
    "            for i in random_indices:\n",
    "                label = \"random_\" + str(i)\n",
    "                clusters[label] = user_preferred_movies[i]\n",
    "        else:\n",
    "            labels, counts = np.unique(cluster_labels[cluster_labels != -1], return_counts=True)\n",
    "\n",
    "            # Get index of most and least common clusters\n",
    "            most_common_cluster = labels[np.argmax(counts)]\n",
    "            least_common_cluster = labels[np.argmin(counts)]\n",
    "\n",
    "            # If they are the same (e.g., all clusters have same size), pick a different one for diversity\n",
    "            if most_common_cluster == least_common_cluster and len(labels) > 1:\n",
    "                # Exclude the most common cluster and pick randomly from the rest\n",
    "                alternative_clusters = [label for label in labels if label != most_common_cluster]\n",
    "                least_common_cluster = np.random.choice(alternative_clusters)\n",
    "\n",
    "            print(f\"Most common cluster: {most_common_cluster}\")\n",
    "            print(f\"Least common cluster: {least_common_cluster}\")\n",
    "\n",
    "            selected_clusters = [most_common_cluster, least_common_cluster]\n",
    "\n",
    "            cluster_mask = ~np.isin(cluster_labels, selected_clusters)\n",
    "            cluster_labels[cluster_mask] = -1 # Mask remaining clusters as noise\n",
    "            print(f\"Cluster labels: {cluster_labels}\")\n",
    "\n",
    "            for i in range(len(user_preferred_movies)):\n",
    "                label = cluster_labels[i]\n",
    "                movie_info = user_preferred_movies[i]\n",
    "                if label == -1:\n",
    "                    continue # Skip noise movies\n",
    "                if str(label) not in clusters:\n",
    "                    clusters[str(label)] = []\n",
    "                clusters[str(label)].append(movie_info)\n",
    "\n",
    "        tasks = list(clusters.items())\n",
    "\n",
    "        def _produce(label, data):\n",
    "            if label.startswith(\"random_\"):\n",
    "                rep = Representant(genres=data[\"genres\"], plot=data[\"plot\"])\n",
    "            else:\n",
    "                limit = min(len(data), 10)  # Limit to 10 movies per cluster since we are using Llama3.1:8b\n",
    "                print(f\"limit: {limit}\")\n",
    "                indices = np.random.choice(len(data), size=limit, replace=False)\n",
    "                cluster_sample = [data[i] for i in indices]\n",
    "                # print input movies\n",
    "                for i, movie in enumerate(cluster_sample):\n",
    "                    print(f\"Movie {i}: {movie['title']} ({movie['genres']}) - {movie['plot']}...\")\n",
    "                rep = self._generate_representant(cluster_sample, self.diversity_stimulus)\n",
    "                # print repreresentant\n",
    "                if rep:\n",
    "                    print(f\"Representant: {rep.genres} - {rep.plot}...\") \n",
    "\n",
    "            if not rep:\n",
    "                return label, None, None\n",
    "\n",
    "            rep_genre_embeddings = self._model.encode([rep.genres])\n",
    "            rep_plot_embeddings = self._model.encode([rep.plot])\n",
    "            rep_embeddings = genre_weight * rep_genre_embeddings + plot_weight * rep_plot_embeddings\n",
    "\n",
    "            return label, rep, rep_embeddings\n",
    "\n",
    "        representants = []\n",
    "        representant_embeddings_dict  = {}\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=1) as pool:\n",
    "            futures = [pool.submit(_produce, lbl, data) for lbl, data in tasks]\n",
    "\n",
    "            for fut in as_completed(futures):\n",
    "                label, rep, emb = fut.result()\n",
    "                if rep is not None:\n",
    "                    representants.append(rep)\n",
    "                    representant_embeddings_dict[label] = emb\n",
    "        \n",
    "        #print(\"\\n--- Generating Diversity Representant ---\")\n",
    "        div_representant = self._generate_diversity_representant(representants, self.diversity_stimulus)\n",
    "        if div_representant:\n",
    "            print(f\"Generated diversity representant:\", div_representant)\n",
    "            rep_genre_embeddings = self._model.encode([div_representant.genres])\n",
    "            rep_plot_embeddings = self._model.encode([div_representant.plot])\n",
    "            rep_embeddings = genre_weight * rep_genre_embeddings + plot_weight * rep_plot_embeddings\n",
    "            representant_embeddings_dict[\"diversity\"] = rep_embeddings\n",
    "        else:\n",
    "            #print(\"Could not generate diversity representant.\")\n",
    "            pass\n",
    "\n",
    "        # Find similar embeddings, movies\n",
    "        used_items = set()\n",
    "        cluster_candidates = {}\n",
    "        for cluster_id, rep_emb in representant_embeddings_dict.items():\n",
    "            similarities = cosine_similarity(rep_emb.reshape(1, -1), emb_matrix)[0]\n",
    "            # multiply similarities by preds item wise\n",
    "            similarities = apply_quantile_transform(similarities.reshape(-1, 1), output_distribution='normal')[0].flatten()\n",
    "            similarities = similarities * relevance_scores[mask]\n",
    "            closest_indices = np.argsort(-similarities)[:k]\n",
    "            top_k_original_indices = original_indices[closest_indices]\n",
    "            cluster_candidates[cluster_id] = [int(i) for i in top_k_original_indices if int(i) not in used_items]\n",
    "\n",
    "        # Create result in round-robin way\n",
    "        # TODO: Use LLM to re-rank the items ? or half of them ?\n",
    "        cluster_ids = list(cluster_candidates.keys())\n",
    "        result = []\n",
    "        i = 0\n",
    "        while len(result) < k and any(cluster_candidates.values()):\n",
    "            cluster_id = cluster_ids[i % len(cluster_ids)]\n",
    "            candidates = cluster_candidates[cluster_id]\n",
    "\n",
    "            if candidates:\n",
    "                candidate = candidates.pop(0)\n",
    "                if candidate not in used_items:\n",
    "                    result.append(candidate)\n",
    "                    used_items.add(candidate)\n",
    "            i += 1\n",
    "\n",
    "        #print(\"LLMprofiling done\")\n",
    "\n",
    "        return result[:k]\n",
    "\n",
    "    def _generate_representant(self, movies_cluster, stimulus: DiversityStimulus):\n",
    "            \n",
    "        handler = self.stimulus_handlers[stimulus]()\n",
    "\n",
    "        return handler.generate_cluster_representant(movies_cluster)\n",
    "    \n",
    "    def _generate_diversity_representant(self, representants, stimulus: DiversityStimulus):\n",
    "\n",
    "        handler = self.stimulus_handlers[stimulus]()\n",
    "\n",
    "        return handler.generate_diversity_representant(representants)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20c91908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B matrix computed\n"
     ]
    }
   ],
   "source": [
    "algo = LLMProfiling(loader=loader, positive_threshold=2.5, l2=500)\n",
    "algo.fit(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de66df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Interstellar (2014)\",\n",
    "    \"The Martian (2015)\",\n",
    "    \"Ad Astra (2019)\",\n",
    "    \"Hercules (1997)\",\n",
    "    \"Percy Jackson & the Olympians: The Lightning Thief (2010)\",\n",
    "    \"Clash of the Titans (2010)\",\n",
    "    \"Fire Island (2022)\",\n",
    "    \"The Menu (2022)\",\n",
    "    \"Madagascar (2005)\",\n",
    "    \"Incredibles 2 (2018)\",\n",
    "    \"Incredibles, The (2004)\",\n",
    "    \"Wheelman (2017)\",\n",
    "    \"Drive (2011)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9ba56b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1 -1  0  0 -1  1  1 -1 -1  1 -1 -1]\n",
      "Most common cluster: 0\n",
      "Least common cluster: 1\n",
      "Cluster labels: [ 0 -1 -1  0  0 -1  1  1 -1 -1  1 -1 -1]\n",
      "limit: 3\n",
      "Movie 0: Clash of the Titans (2010) (Action, Adventure, Drama, Fantasy) - Perseus, a demigod and the son of Zeus, battles the minions of Hades and the Underworld in order to stop them from conquering Olympus and Earth....\n",
      "Movie 1: Percy Jackson & the Olympians: The Lightning Thief (2010) (Adventure, Fantasy) - A teenager discovers he&#x27;s the descendant of a Greek god and sets out on an adventure to settle an on-going battle between the gods....\n",
      "Movie 2: Hercules (1997) (Adventure, Animation, Children, Comedy, Musical) - The son of Zeus and Hera is stripped of his immortality as an infant and must become a true hero in order to reclaim it....\n",
      "Representant: Action, Adventure, Drama, Fantasy - In a world where gods and mortals coexist, a young hero discovers they're the last living heir of a powerful deity. As they embark on an epic quest to reclaim their divine heritage, they must confront formidable monsters and rival demigods to prevent an impending war between Olympus and Earth, all while navigating the complexities of their own identity....\n",
      "limit: 3\n",
      "Movie 0: Interstellar (2014) (Sci-Fi, IMAX) - When Earth becomes uninhabitable in the future, a farmer and ex-NASA pilot, Joseph Cooper, is tasked to pilot a spacecraft, along with a team of researchers, to find a new planet for humans....\n",
      "Movie 1: Ad Astra (2019) (Adventure, Drama, Mystery, Sci-Fi, Thriller) - Astronaut Roy McBride undertakes a mission across an unforgiving solar system to uncover the truth about his missing father and his doomed expedition that now, 30 years later, threatens the universe....\n",
      "Movie 2: The Martian (2015) (Adventure, Drama, Sci-Fi) - An astronaut becomes stranded on Mars after his team assume him dead, and must rely on his ingenuity to find a way to signal to Earth that he is alive and can survive until a potential rescue....\n",
      "Representant: Sci-Fi, Adventure, Drama - Astronaut Emma Taylor embarks on a perilous journey to the farthest reaches of the solar system in search of her missing sister, who vanished while investigating an abandoned research station. As she navigates treacherous asteroids and encounters strange occurrences, Emma discovers that her sister's disappearance is linked to an ancient alien technology hidden on one of Jupiter's moons. With time running out and resources dwindling, Emma must rely on her wit and ingenuity to unravel the mystery of her sister's fate and prevent a catastrophic convergence of celestial events that threatens the entire galaxy....\n",
      "Generated diversity representant: genres='Mystery, Thriller, Drama' plot=\"In the city of echoes, where memories can be transferred from one person to another through a mysterious phenomenon known as 'The Share', detective Maya Singh is tasked with solving a series of inexplicable murders. As she delves deeper into the case, she discovers that each victim was somehow connected to her own past, and that their memories hold the key to unraveling the dark conspiracy behind The Share, threatening to upend the very fabric of society.\"\n"
     ]
    }
   ],
   "source": [
    "# get movie ids from titles\n",
    "movie_ids = loader.movies_df[loader.movies_df['title'].isin(titles)]['movieId'].index.tolist()\n",
    "res = algo.predict(\n",
    "    selected_items=movie_ids,\n",
    "    filter_out_items=movie_ids,\n",
    "    k=10,\n",
    "    dominant_stimulus_weight=0.8,\n",
    "    dominant_stimulus=DiversityStimulus.PLOT\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11de3e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies:\n",
      "6324: Percy Jackson: Sea of Monsters (2013) (Adventure, Children, Fantasy) - In order to restore their dying safe haven, the son of Poseidon and his friends embark on a quest to...\n",
      "9402: 65 (2023) (Sci-Fi, Thriller) - An astronaut crash lands on a mysterious planet only to discover he&#x27;s not alone....\n",
      "4563: 300 (2007) (Action, Fantasy, War, IMAX) - In the ancient battle of Thermopylae, King Leonidas and 300 Spartans fight against Xerxes and his ma...\n",
      "5948: Wrath of the Titans (2012) (Action, Adventure, Fantasy, IMAX) - Perseus braves the treacherous underworld to rescue his father, Zeus, captured by his son, Ares, and...\n",
      "8396: Roma (2018) (Drama) - A year in the life of a upper-middle-class family&#x27;s maid in Mexico City in the early 1970s....\n",
      "6672: Nightcrawler (2014) (Crime, Drama, Thriller) - A petty thief desperate for work muscles into the world of crime journalism and becomes the star of ...\n",
      "7358: Gods of Egypt (2016) (Adventure, Fantasy) - Mortal hero Bek teams with the god Horus in an alliance against Set, the merciless god of darkness, ...\n",
      "5133: Moon (2009) (Drama, Mystery, Sci-Fi, Thriller) - Astronaut Sam Bell has a quintessentially personal encounter toward the end of his three-year stint ...\n",
      "5451: Inception (2010) (Action, Crime, Drama, Mystery, Sci-Fi, Thriller, IMAX) - A thief who steals corporate secrets through the use of dream-sharing technology is given the invers...\n",
      "8725: Sherlock: The Abominable Bride (2016) (Crime, Drama, Mystery) - Sherlock Holmes and Dr. Watson find themselves in 1890s London in this Christmas special....\n"
     ]
    }
   ],
   "source": [
    "res_movies = loader.movies_df.iloc[res]\n",
    "print(\"Recommended movies:\")\n",
    "for i, movie in res_movies.iterrows():\n",
    "    print(f\"{i}: {movie['title']} ({movie['genres']}) - {movie['plot'][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
